# BinaryLLM — Phase 1 Progress Log

> Location (suggested): `docs/phase1/phase1_progress_log.md`

This document tracks everything completed so far for **BinaryLLM – Phase 1 (Binary Embedding & Similarity Engine)**, from research to architecture design and the first engineering task (T1).

---

## 1. Project Context

- **Project:** `binary_llm` (separate from `nsla-v2`, in its own folder/repo).
- **Long‑term goal:** Explore **1‑bit / low‑bit latent spaces** for LLMs to reduce memory, bandwidth and energy, while preserving usable semantic performance.
- **Current focus (Phase 1):** Build a rigorous, reproducible **Binary Embedding & Similarity Engine v0.1** targeting **H1** from the research report:
  - *H1 (informal):* “With sufficiently long binary codes and proper projections, binary embeddings can preserve nearest‑neighbor structure and retrieval quality relative to float embeddings.”

---

## 2. Research Phase (Pre‑Engineering)

### 2.1 High‑Rigor Research Pipeline

We set up a **two‑agent research loop**:

- **`/researcher` (Researcher-BinaryLLM)**
  - Role: senior research engineer.
  - Duties: exhaustive literature review on BNNs, binary embeddings, 1‑bit quantization, similarity preservation, hardware/energy aspects.
  - Output structure: domain & motivation, tabular literature summary, gaps, hypotheses (H1, H2, …), and a roadmap.
  - Hard constraints: no invented papers, no hallucinated algorithms, explicit uncertainty tagging, academic tone.

- **`/validator` (Validator-BinaryLLM — Jensen Huang Edition)**
  - Role: hostile research validator.
  - Duties: attack every claim, check math, literature alignment, feasibility, novelty, integrity.
  - Output format: structured JSON (`verdict`, `critical_flaws`, `required_fixes`, `math_validation`, `literature_alignment`, `feasibility`, `novelty_score`, `integrity_flags`).
  - Policy: REJECT anything non‑verifiable or mathematically vague.

### 2.2 Iterative Validation to v2 Report

Steps performed:

1. **Initial research report (v1)** generated by `/researcher`.
2. **Validator runs** returned **REJECT** twice, with detailed required fixes:
   - Missing explicit math (binarization, similarity preservation, rate–distortion).
   - Approximate / speculative hardware & energy claims.
   - No unified, self‑contained v2 report.
   - Incomplete experiment protocol and literature table.
3. `/researcher` produced a **unified BinaryLLM Research Report v2** including:
   - Formal definitions of binarization (sign, scaled‑sign) and STE.
   - Derivation of the random‑hyperplane result `P[sign(X) ≠ sign(Y)] = θ/π`.
   - Explanation of how normalized Hamming distance approximates angular distance.
   - Rate–distortion argument for 1‑bit latents using Gaussian R(D).
   - Symbolic resource models for memory, FLOPs, and energy (no speculative numerics).
   - Curated literature table (BNNs, binary embeddings, low‑bit LLMs, hardware).
   - Concrete experimental protocol (datasets, metrics, hypotheses, pass/fail criteria).
4. `/validator` finally returned **PASS** on the v2 report and then again on the cleaned **markdown report file**:
   - `binaryllm_report_v2.md` (stored in `docs/` / project root).

### 2.3 Formatter Agent for Final Report

- We introduced `/formatter_binaryllm` to:
  - Take the validated research content.
  - Render it into a **clean, professional markdown report** with equations and structure.
- The resulting `binaryllm_report_v2.md` was re‑validated by `/validator` and achieved **PASS**.

### 2.4 arXiv‑Style Paper Draft

- A first **arXiv‑style paper draft** was produced (e.g. `binaryllm_paper_arxiv_v1.md`):
  - Title: **“BinaryLLM — Towards 1‑Bit Latent Spaces for Efficient LLMs”**.
  - Contains: abstract, introduction, background, method, theory, experiments plan, systems analysis, limitations, and future work.
- This draft is meant for future polishing when the prototype and experiments are complete (not for publication yet).

---

## 3. Project Rules for `binary_llm`

We installed **project‑specific rules** (separate from NSLA-v2) in Cursor → Project Rules for the `binary_llm` folder.

Key properties:

- **Scope:** Rules apply only when the `binary_llm` folder is the active project.
- **Focus:** Research + early engineering discipline (not yet full “military strict” coding mode like NSLA-v2).
- **Enforced behaviors:**
  - No hallucinations / invented literature.
  - Explicit citations and verifiability for research.
  - Explicit invariants for binary math (`{-1,+1}` internal, `{0,1}` storage; explicit bit‑widths).
  - Config‑driven, reproducible experiments.
  - Tests required for any behavioral change once engineering starts.

These rules are the backbone for the next phases (architecture and implementation).

---

## 4. Phase 1 Architecture — `/architect_binaryllm`

### 4.1 Objective

Design a **Phase 1 MVP architecture** for:

> **Binary Embedding & Similarity Engine v0.1**

that:

- Consumes **precomputed float embeddings** from external encoders.
- Applies projection + binarization to produce **binary codes**.
- Evaluates similarity preservation, retrieval quality, and simple classification.
- Logs all results in structured, reproducible form.
- Targets **H1** explicitly.

No training loops or full LLM integration in Phase 1; it’s a controlled “binary embedding lab.”

### 4.2 Architecture v1 → v2 (after Validation)

The initial `/architect_binaryllm` plan was:

- A modular structure with `src/core`, `src/quantization`, `src/eval`, `src/utils`, `src/experiments`, `src/variants`, `tests`.
- Detailed modules:
  - `core/embeddings.py`, `core/datasets.py`.
  - `quantization/binarization.py`, `quantization/packing.py`.
  - `eval/similarity.py`, `eval/retrieval.py`, `eval/classification.py`.
  - `utils/io.py`, `utils/seed.py`, `utils/config.py`, `utils/logging.py`.
  - `experiments/configs/...`, `experiments/runners/phase1_binary_embeddings.py`.
  - `variants/binary_embedding_engine.py` facade.
- Test plan for binarization, packing, similarity, retrieval, IO/config, and integration.

#### 4.2.1 Validator Feedback (REVISE)

`/validator_binaryllm` flagged several issues:

- Missing components:
  - Artifact/result schema definition.
  - Explicit config schema.
  - Dataset catalog abstraction.
  - Hypothesis IDs (e.g. `H1`) not linked to runs/logs.
  - No explicit place for synthetic/golden datasets.
- Inconsistencies:
  - Ambiguous ownership between `BinaryCodeBatch` and packing utilities.
  - Overlap between `variants/binary_embedding_engine.py` and experiment runner.
  - Classification scope unclear vs core H1 focus.
  - Git hash logging described as “optional” instead of first‑class.
- Test coverage gaps:
  - No tests for logging schema, failure paths, config evolution, deterministic behavior, or basic runtime sanity.
- Research alignment issues:
  - Normalization not strictly enforced though theory assumes unit‑norm.
  - Random projection assumptions for H1 not fully wired into configs.

#### 4.2.2 Revised Architecture (PASS)

We revised the plan, then re‑validated it. Final architecture highlights:

- **Tight H1 focus:** Phase 1 is exclusively about binary embeddings, similarity and retrieval.
- **Clear module boundaries:**
  - `BinaryCodeBatch` handles logical codes; bit‑packing lives in `quantization/packing.py`.
  - `variants/binary_embedding_engine.py` is a reusable facade; experiment runners are thin wrappers around it.
- **Explicit schemas:**
  - **Config schema** for Phase 1 (encoder, dataset, code_bits, projection_type, metrics, seeds, hypotheses, etc.).
  - **Result schema** (metrics, encoder/dataset IDs, code_bits, projection params, seeds, git_hash, hypotheses).
- **Dataset catalog:**
  - Central mapping for supported datasets/encoders, formats and expected columns.
- **Hypothesis tracking:**
  - Each Phase 1 experiment carries `hypotheses: ["H1"]` in configs and logs.
- **Synthetic & golden datasets:**
  - Designated location (e.g. `tests/data/phase1_synthetic/`) for tiny controlled datasets + golden artifacts.
- **Determinism & failure modes:**
  - Seeds set via `utils/seed.py`.
  - Structured errors with stage/variant/dataset context.
  - Tests for failure paths and logging structure.

`/validator_binaryllm` returned **PASS** on the revised architecture and recommended freezing it as the Phase 1 spec before any `/engineer` work.

---

## 5. Engineering Phase — T1 (Directory Skeleton)

### 5.1 Task T1 Definition

> **T1 — Establish core project layout**

- Create empty package skeletons:
  - `src/`
  - `src/core/`
  - `src/quantization/`
  - `src/eval/`
  - `src/utils/`
  - `src/experiments/`
  - `src/experiments/configs/`
  - `src/experiments/runners/`
  - `src/variants/`
  - `tests/`
- Each directory must contain an `__init__.py` with **only a docstring** (no logic).
- Add a minimal **smoke test**:
  - `tests/test_package_imports.py`
  - Verifies importability of all packages listed above under `pytest -q`.
- No implementation, no binarization logic, no evaluation code.

### 5.2 T1 — First Engineer Attempt

- `/engineer_binaryllm` (Codex 5.1 High) created the basic directory layout and `__init__.py` files.
- Issues found by reviewer:
  - Missing `src/experiments/configs/` and `src/experiments/runners/` subpackages.
  - No `tests/test_package_imports.py` smoke test.
- Verdict: **REVISE**.

### 5.3 T1 — Revised Engineer Attempt

We gave `/engineer_binaryllm` a precise fix prompt:

- Add missing directories:
  - `src/experiments/configs/__init__.py`
  - `src/experiments/runners/__init__.py`
- Create `tests/test_package_imports.py` importing:
  - `src`
  - `src.core`
  - `src.quantization`
  - `src.eval`
  - `src.utils`
  - `src.experiments`
  - `src.variants`
  - `src.experiments.configs`
  - `src.experiments.runners`
- Ensure no extra logic is added anywhere.

### 5.4 Hostile Review on T1

- `/hostile_binaryllm` reviewed the second T1 patch with a strict checklist:
  - All required packages present.
  - `__init__.py` files docstring‑only.
  - Smoke test exists and only imports packages.
  - No extra logic, no scope creep.
- Verdict: **PASS**.

Final hostile JSON (summary):

> “T1’s directory skeleton now fully matches the approved architecture: all required packages exist, __init__.py files are docstring-only, and the smoke test cleanly validates imports. There is no scope creep or hidden logic. This patch is safe to freeze as the canonical T1 skeleton.”

T1 is now **frozen** as the canonical skeleton for Phase 1.

---

## 6. Current State Summary

As of now, for the `binary_llm` project we have:

1. **Validated research foundation**:
   - `binaryllm_report_v2.md` (PASS by validator) with math, literature, hypotheses and experiment protocol.
   - arXiv-style paper draft ready for later polishing.

2. **Strong project rules** for `binary_llm`:
   - Research discipline (no hallucinations, verifiable citations).
   - Explicit binary math and bit-width conventions.
   - Reproducible, config-driven experiments.

3. **Validated Phase 1 architecture** (PASS by validator):
   - Clear module layout and responsibilities.
   - Config & result schemas.
   - Dataset catalog.
   - Hypothesis tracking and golden tests plan.

4. **Engineering task T1 completed**:
   - Directory skeleton implemented.
   - Smoke test in place.
   - Hostile reviewer PASS.

We are now ready to move to **T2 (Embedding & Dataset Abstractions)**, strictly following:

- The approved architecture.
- The /engineer → /hostile → /validator loop.
- Test‑first, minimal‑diff, zero‑hallucination discipline.

---

## 7. Suggested Next Steps

1. **Define T2 prompt for `/engineer_binaryllm`**
   - Implement `FloatEmbeddingBatch`, `BinaryCodeBatch`, and minimal dataset wrappers (`core/embeddings.py`, `core/datasets.py`).
   - With corresponding unit tests.

2. **Prepare `/hostile_binaryllm` + `/validator_binaryllm` prompts for T2**
   - Hostile review of shapes, invariants, and failure paths.
   - Validator check for alignment with binaryllm_report_v2 and project rules.

3. **Keep this log updated**
   - Append new sections to `docs/phase1/phase1_progress_log.md` after each major task (T2, T3, … T10).


---

## Checkpoint 2 — Core Embeddings + Binarization Complete

**Status (Phase 1 – Binary Embedding Lab)**
- ✅ T1 — Directory skeleton (`src/`, `tests/`, subpackages) created and smoke-tested.
- ✅ T2A — `FloatEmbeddingBatch` / `BinaryCodeBatch` core abstractions implemented with:
  - Shape, dtype, normalization, and `{−1,+1}` / `{0,1}` invariants.
  - Clear error messages and deterministic behavior.
- ✅ T2B — `EmbeddingDataset` / `QueryDataset` wired to the catalog with strict validation:
  - Dataset/encoder specs enforced from a central registry.
  - Error paths and edge cases fully covered by tests.
- ✅ Dataset catalog module + full test suite:
  - Invariants, error-path behavior, and determinism fully validated.
- ✅ T3 — Projection + binarization operators:
  - Random hyperplane projections consistent with BinaryLLM report math.
  - `binarize_sign` and related ops deterministic and on-spec.
  - Hamming vs. angle sanity checks implemented in tests.
- ✅ Diagnostic contract hardening:
  - Regexes for `codes_01` and `codes_pm1` corrected and aligned with implementation messages.
  - All core-embeddings tests and full suite passing after hostile review from a fresh context.

**Hostile Review Summary**
- Latest `/hostile_binaryllm` verdicts for T2A, T2B, T3, and the diagnostic fixes are all **PASS**.
- No scope creep detected, no hidden behavior, no API drift.
- Residual risks are explicitly documented (e.g., tests tightly bound to specific diagnostic wording).

**Open Work for Phase 1**
Next planned tasks (per approved architecture):
1. **T4 – Bit packing/unpacking**
   - `{0,1}` → packed 64-bit buffers, with a documented, GPU-conscious layout.
   - Round-trip and edge-case tests.
2. **T5 – Similarity metrics module**
   - Cosine (float) vs. Hamming (binary) similarity, correlation metrics.
3. **T6 – Retrieval metrics**
   - Top‑k neighbor search, overlap, nDCG@k, Recall@k.
4. **T7 (aux) – Classification evaluation**
   - Simple classifiers on float vs. binary embeddings (evaluation-only).
5. **T8 – Config, seed, IO, logging utilities**
   - Config schema enforcement, deterministic seeding, structured logging.
6. **T9 – Phase 1 experiment runner**
   - End‑to‑end pipeline for H1 experiments.
7. **T10 – Binary embedding engine façade**
   - Reusable interface over the Phase 1 pipeline.

The next immediate focus, if we proceed in order, is **T4 – Bit packing/unpacking**, again following the loop:
- `/tester_binaryllm` defines/extends tests,
- `/engineer_binaryllm` implements the code,
- `/hostile_binaryllm` performs hostile validation.

