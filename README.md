<![CDATA[<div align="center">

# ğŸ”¢ BinaryLLM

**Towards 1-Bit Latent Spaces for Efficient Large Language Models**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Tests: 157 Passing](https://img.shields.io/badge/tests-157%20passing-brightgreen.svg)](#test-suite)
[![Phase: 1 Complete](https://img.shields.io/badge/phase-1%20complete-success.svg)](#phase-1-overview)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

*A research-first framework exploring whether binary (1-bit) representations can serve as a viable computational substrate for LLM embeddings while preserving semantic structure.*

[Overview](#overview) â€¢
[Quick Start](#quick-start) â€¢
[Architecture](#architecture) â€¢
[Usage](#usage) â€¢
[Results](#phase-1-results) â€¢
[Roadmap](#roadmap) â€¢
[Citation](#citation)

</div>

---

## Overview

**BinaryLLM** investigates the fundamental question: *Can we compress high-dimensional float embeddings to 1-bit binary codes while preserving their semantic neighborhoods?*

This repository implements **Phase 1** of the BinaryLLM research programâ€”a deterministic binary embedding pipeline that:

- ğŸ¯ **Projects** float embeddings to binary codes via Gaussian random hyperplanes
- ğŸ“Š **Evaluates** similarity preservation (cosine â†” Hamming correlation)
- ğŸ” **Measures** retrieval quality (top-k overlap, nDCG, recall)
- ğŸ·ï¸ **Tests** classification degradation with centroid classifiers
- âœ… **Guarantees** full determinism and reproducibility

### Why Binary Embeddings?

| Aspect | Float32 | Binary (1-bit) | Improvement |
|--------|---------|----------------|-------------|
| Storage per dim | 32 bits | 1 bit | **32Ã— smaller** |
| Similarity compute | FLOPs (dot product) | XOR + popcount | **~10Ã— faster** |
| Memory bandwidth | High | Minimal | Significant for KV-cache |

### Phase 1 Goals

1. **Validate Hypothesis H1**: Binary embeddings preserve nearest-neighbor structure with sufficient code length
2. **Establish deterministic baselines**: Reproducible metrics for future phases
3. **Freeze contracts**: Stable APIs, schemas, and golden tests for Phase 2+

---

## Quick Start

### Prerequisites

- Python â‰¥ 3.10
- NumPy â‰¥ 1.24
- PyYAML â‰¥ 6.0
- SciPy â‰¥ 1.10 (for metrics)

### Installation

```bash
# Clone the repository
git clone https://github.com/matte1782/binaryllm.git
cd binaryllm

# Create virtual environment
python -m venv .venv

# Activate (Linux/macOS)
source .venv/bin/activate

# Activate (Windows)
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run Your First Experiment

```bash
# Run the golden synthetic experiment
python -m src.experiments.runners.phase1_binary_embeddings \
    --config tests/data/phase1_golden/config_phase1_synthetic_v1.yaml
```

### Run Tests

```bash
# Run all 157 tests
pytest -q

# Run with coverage
pytest --cov=src --cov-report=term-missing
```

---

## Architecture

```
BinaryLLM Phase 1 Architecture
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Precomputed Float Embeddings                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 1 Binary Embedding Engine                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Runner  â”‚â†’ â”‚ FaÃ§ade  â”‚â†’ â”‚Quantizationâ”‚â†’ â”‚   Evaluation    â”‚  â”‚
â”‚  â”‚ (I/O)   â”‚  â”‚(Pipeline)â”‚  â”‚(Binarize)  â”‚  â”‚(Sim/Ret/Class) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                         â”‚
                   â–¼                         â–¼
          Result Dict (RAM)          Structured Logs (JSON)
```

### Module Structure

```
src/
â”œâ”€â”€ core/                    # Dataset catalog & embedding containers
â”‚   â”œâ”€â”€ dataset_catalog.py   # Registry for datasets and encoders
â”‚   â”œâ”€â”€ datasets.py          # Dataset wrappers with validation
â”‚   â””â”€â”€ embeddings.py        # Float/Binary embedding containers
â”‚
â”œâ”€â”€ quantization/            # Binary transformation pipeline
â”‚   â”œâ”€â”€ binarization.py      # Random projection + sign binarization
â”‚   â””â”€â”€ packing.py           # Bit packing to uint64 (LSB-first)
â”‚
â”œâ”€â”€ eval/                    # Evaluation metrics
â”‚   â”œâ”€â”€ similarity.py        # Cosine/Hamming + Spearman correlation
â”‚   â”œâ”€â”€ retrieval.py         # Top-k overlap, nDCG, recall
â”‚   â””â”€â”€ classification.py    # Centroid classifier + degradation
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ runners/
â”‚       â””â”€â”€ phase1_binary_embeddings.py  # Main experiment runner
â”‚
â”œâ”€â”€ variants/
â”‚   â””â”€â”€ binary_embedding_engine.py       # Core faÃ§ade (BinaryEmbeddingEngine)
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ config.py            # YAML/JSON config loader + validation
    â”œâ”€â”€ logging.py           # Structured JSON logging (v2 schema)
    â”œâ”€â”€ seed.py              # Global seed management
    â””â”€â”€ io.py                # File I/O helpers
```

### Key Design Principles

| Principle | Implementation |
|-----------|----------------|
| **Separation of Concerns** | Runner handles I/O; FaÃ§ade handles math; no cross-contamination |
| **Determinism** | Same seed + inputs = identical outputs, always |
| **Explicit Errors** | Structured error pipeline with named stages |
| **Schema Stability** | Result/Log Schema v2 is frozen and tested |

---

## Usage

### Configuration

Create a YAML config file:

```yaml
# my_experiment.yaml
runner: phase1_binary_embeddings
encoder_name: my_encoder
dataset_name: my_dataset
code_bits: 64                    # 32, 64, 128, or 256
projection_type: gaussian        # Only "gaussian" in Phase 1
seed: 42
tasks:
  - similarity
  - retrieval
  - classification
embedding_files:
  - path/to/embeddings.npy
classification_labels: path/to/labels.npy
output_dir: runs/my_experiment/
```

### Programmatic API

```python
from src.experiments.runners.phase1_binary_embeddings import run_phase1_experiment

# Run experiment
result = run_phase1_experiment("path/to/config.yaml")

# Check status
if result["status"] == "success":
    print(f"Cosine-Hamming Spearman: {result['similarity_metrics']['cosine_hamming_spearman']:.4f}")
    print(f"Top-k Overlap: {result['retrieval_metrics']['topk_overlap']['k=3']:.4f}")
    print(f"Accuracy Delta: {result['classification_metrics']['accuracy_delta']:.4f}")
else:
    print(f"Error at stage '{result['error']['stage']}': {result['error']['message']}")
```

### Using the Engine Directly

```python
import numpy as np
from src.core.dataset_catalog import get_dataset_spec, get_encoder_spec
from src.variants.binary_embedding_engine import BinaryEmbeddingEngine

# Load specs
encoder = get_encoder_spec("synthetic_encoder_4d")
dataset = get_dataset_spec("phase1_synthetic_toy")

# Create engine
engine = BinaryEmbeddingEngine(
    encoder_spec=encoder,
    dataset_spec=dataset,
    code_bits=64,
    projection_type="gaussian",
    seed=42,
    normalize=True,
)

# Run pipeline
embeddings = np.random.randn(100, 4).astype(np.float32)
labels = np.random.randint(0, 3, size=100)

result = engine.run(
    embeddings,
    metrics=["similarity", "retrieval", "classification"],
    retrieval_k=5,
    classification_labels=labels,
    return_full_code_bits=True,
)

# Access binary codes
binary_codes = result["binary_codes"]
print(f"PM1 codes shape: {binary_codes['pm1'].shape}")     # (100, 64)
print(f"Packed codes shape: {binary_codes['packed'].shape}") # (100, 1) for 64-bit
```

---

## Phase 1 Results

### Golden Synthetic Dataset Performance

| Metric | Value | Notes |
|--------|-------|-------|
| Cosine-Hamming Spearman | ~0.94 | Strong rank correlation preserved |
| Top-3 Overlap | ~0.91 | High neighbor consistency |
| nDCG@3 | ~0.95 | Excellent ranking quality |
| Float Accuracy | 1.00 | Perfect on synthetic data |
| Binary Accuracy | ~0.92 | Expected degradation |
| Accuracy Delta | -0.08 | Confirms H1 degradation contract |

### Test Suite

- **157 tests** covering all modules
- **100% determinism** verified via golden regression
- **Cross-platform** tested (Linux, macOS, Windows)

---

## Environment & Requirements

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| Python | 3.10 | 3.11+ |
| RAM | 4 GB | 8 GB+ |
| Disk | 100 MB | 500 MB |

### Dependencies

```
numpy>=1.24.0
scipy>=1.10.0
pyyaml>=6.0
torch>=2.0.0  # Optional, for GPU metadata
pytest>=7.0.0  # Development only
```

See `requirements.txt` for pinned versions.

---

## Roadmap

### âœ… Phase 1: Binary Embedding Engine (Complete)

- [x] Gaussian random projection
- [x] Sign binarization with {-1,+1} â†’ {0,1} mapping
- [x] LSB-first bit packing to uint64
- [x] Similarity, retrieval, and classification metrics
- [x] Deterministic pipeline with golden tests
- [x] Structured logging (Schema v2)

### ğŸ”œ Phase 2: Binary KV-Cache (Planned)

- [ ] Binary attention key/value representations
- [ ] XNOR-popcount attention kernels
- [ ] Memory bandwidth benchmarks
- [ ] Long-context scaling experiments

### ğŸ”® Phase 3: Binary Transformer Components (Research)

- [ ] 1-bit projection layers
- [ ] Binary MLP blocks
- [ ] Hybrid binary/low-bit architectures

### ğŸš€ Phase 4: Full BinaryLLM Inference (Vision)

- [ ] End-to-end binary inference pipeline
- [ ] Production-ready CUDA kernels
- [ ] Integration with existing LLM frameworks

---

## Project Structure

```
binaryllm/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ LICENSE                   # MIT License
â”œâ”€â”€ CHANGELOG.md              # Version history
â”œâ”€â”€ CONTRIBUTORS.md           # Project contributors
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ pyproject.toml            # Modern Python packaging
â”œâ”€â”€ .gitignore                # Git ignore rules
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ core/                 # Core abstractions
â”‚   â”œâ”€â”€ quantization/         # Binarization pipeline
â”‚   â”œâ”€â”€ eval/                 # Evaluation metrics
â”‚   â”œâ”€â”€ experiments/          # Experiment runners
â”‚   â”œâ”€â”€ variants/             # Engine implementations
â”‚   â””â”€â”€ utils/                # Utilities
â”‚
â”œâ”€â”€ tests/                    # Test suite (157 tests)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ phase1_golden/    # Golden regression artifacts
â”‚   â””â”€â”€ test_*.py             # Test modules
â”‚
â”œâ”€â”€ scripts/                  # Helper scripts
â”‚   â””â”€â”€ generate_phase1_golden.py
â”‚
â””â”€â”€ docs/                     # Documentation
    â”œâ”€â”€ architecture/         # Architecture docs
    â”œâ”€â”€ artifacts/            # Phase artifacts
    â””â”€â”€ papers_arxiv/         # Research papers
```

---

## Author

**Matteo Panzeri**  
*Artificial Intelligence Bachelor Student*  
*University of Pavia, Italy*

ğŸ“§ **Contact:**
- Personal: [matteo1782@gmail.com](mailto:matteo1782@gmail.com)
- Academic: [matteo.panzeri01@universitadipavia.it](mailto:matteo.panzeri01@universitadipavia.it)

---

## Citation

If you use BinaryLLM in your research, please cite:

```bibtex
@software{panzeri2025binaryllm,
  author = {Panzeri, Matteo},
  title = {BinaryLLM: Towards 1-Bit Latent Spaces for Efficient Large Language Models},
  year = {2025},
  url = {https://github.com/matte1782/binaryllm},
  note = {Phase 1: Binary Embedding Engine}
}
```

---

## Contributing

Contributions are welcome! Please read the following before contributing:

1. **Phase 1 is frozen** â€” No changes to core logic without explicit approval
2. **Run all tests** â€” `pytest -q` must pass (157 tests)
3. **Maintain determinism** â€” Same seed must produce identical outputs
4. **Follow conventions** â€” See existing code for style guidelines

See [CONTRIBUTORS.md](CONTRIBUTORS.md) for contributor information.

---

## License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">

**BinaryLLM** â€” Compressing knowledge, preserving meaning.

*Built with rigor. Designed for impact.*

â­ Star this repo if you find it useful!

</div>
]]>